{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting data \n",
    "#The data can be downloaded from the link:https://www.kaggle.com/dalpozz/creditcardfraud/downloads/creditcardfraud.zip\n",
    "data=pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe0161cffd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0161cf650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot('Class',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Firstly we will make some transformations on the data,more specifically on the Amount column so as to bring it in line with the anomalized features. **For this,we wiil be using the StandardScaler Library and then after that we will be firstly breaking down the data and separate them as Feature_Variables and Target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sk/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>Normalized_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10        ...               V21       V22  \\\n",
       "0  0.098698  0.363787  0.090794        ...         -0.018307  0.277838   \n",
       "1  0.085102 -0.255425 -0.166974        ...         -0.225775 -0.638672   \n",
       "2  0.247676 -1.514654  0.207643        ...          0.247998  0.771679   \n",
       "3  0.377436 -1.387024 -0.054952        ...         -0.108300  0.005274   \n",
       "4 -0.270533  0.817739  0.753074        ...         -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \\\n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0   \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0   \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0   \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0   \n",
       "\n",
       "   Normalized_Amount  \n",
       "0           0.244964  \n",
       "1          -0.342475  \n",
       "2           1.160686  \n",
       "3           0.140534  \n",
       "4          -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "data['Normalized_Amount']=sc.fit_transform(data['Amount'].reshape(-1,1))\n",
    "data=data.drop(['Time','Amount'],axis=1)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that in from the countplot as well as the value_counts function that the data is imbalanced because we can see that in the target variables that there are only 492 Class 1 entries and 284315 Class 0 entries, so we have to balance the data so that predictive modelling can be done. \n",
    "But before doing that we have to implement the fit transform on the Amount.\n",
    "\n",
    "**Now the bigger problem we are facing is that the data is skewed and even if we want to apply and Predictive Modelling, it won't produce any fruitful results.Now, as we have seen that the data is imbalanced and the predictive modeling approach will consider the Class 1 results to be outliers because they are very less in number,hence it will try to produe results for one class only and neglecting other class altogether.**\n",
    "\n",
    "There can be many approached such as Undersampling, oversampling, SMOTE and Algorithmic Ensemble Techniques.\n",
    "- Undersampling - In this case we take 10% samples from the Non-Fraud instances anf combine with the Fraud instances.The main advantage of this approach is that it improves the Run time by reducing the number of training examples.\n",
    "- Oversampling - In this approach,we increase the number of instances in minority class by randomly replicating them in order to present a higher proportion of minority class in the sample.\n",
    "- SMOTE- In this approach, we try to avoid overfitting which occurs when exact replicas of minority instances are added to the dataset.So,a subset is taken from minority set and then the new synthetic similar instances are create.These instances are added to the original dataset.SMOTE is a combination of Undersampling and Oversampling but it reduces the disadvantages of replicating the dataset.\n",
    "- In this scnerio, we will be using the Undersampling technique such that we create the dataset by 50/50 ratio.This will be done by randomly selecting 'x' number of samples from the majority class where 'x' is total number of samples in the minority class.\n",
    "\n",
    "**For further knowledge on how to handle the imbalanced data for predictive modeling,you can visit the link:https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Resampling data into features and targets datasets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=data.ix[:,data.columns!='Class']\n",
    "y=data.ix[:,data.columns=='Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9       V10        ...               V20       V21  \\\n",
      "0  0.098698  0.363787  0.090794        ...          0.251412 -0.018307   \n",
      "1  0.085102 -0.255425 -0.166974        ...         -0.069083 -0.225775   \n",
      "2  0.247676 -1.514654  0.207643        ...          0.524980  0.247998   \n",
      "3  0.377436 -1.387024 -0.054952        ...         -0.208038 -0.108300   \n",
      "4 -0.270533  0.817739  0.753074        ...          0.408542 -0.009431   \n",
      "\n",
      "        V22       V23       V24       V25       V26       V27       V28  \\\n",
      "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
      "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
      "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
      "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
      "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
      "\n",
      "   Normalized_Amount  \n",
      "0           0.244964  \n",
      "1          -0.342475  \n",
      "2           1.160686  \n",
      "3           0.140534  \n",
      "4          -0.073403  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "   Class\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n"
     ]
    }
   ],
   "source": [
    "print(x.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Counting the number of fraud records\n",
    "number_fraud_records=len(data[data['Class']==1])\n",
    "\n",
    "#Indices of the fraud records\n",
    "fraud_indices=np.array(data[data['Class']==1].index)\n",
    "\n",
    "#Indices of Normal records i.e. the records that are not faulty\n",
    "normal_indices=data[data['Class']==0].index\n",
    "\n",
    "#Out of the normal_indices,randomly select the 'x' records randomly\n",
    "random_normal_indices=np.random.choice(normal_indices,size=number_fraud_records,replace=False)\n",
    "random_normal_indices=np.array(random_normal_indices)\n",
    "\n",
    "#Appending the 2 indices\n",
    "under_sample_indices=np.concatenate([fraud_indices,random_normal_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sk/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#Under sampled data\n",
    "under_sample_data=data.iloc[under_sample_indices,:]\n",
    "total=len(under_sample_data)\n",
    "class0=len(under_sample_data[under_sample_data['Class']==0])\n",
    "class1=len(under_sample_data[under_sample_data['Class']==1])\n",
    "#Unders ampled features\n",
    "x_sample=under_sample_data.ix[:,under_sample_data.columns!='Class']\n",
    "#Under sampled targets\n",
    "y_sample=under_sample_data.ix[:,under_sample_data.columns=='Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Percentage of normal transactions: ', 0.5)\n",
      "('Percentage of fraud transactions: ', 0.5)\n",
      "('Total number of transactions: ', 984)\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of normal transactions: \",float(class0)/(total))\n",
    "print(\"Percentage of fraud transactions: \",float(class1)/(total))\n",
    "print(\"Total number of transactions: \",total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of transactions in training set:', 190820)\n",
      "('Number of transactions in testing set:', 93987)\n",
      "('Total number of transactions are:', 284807)\n",
      "Undersampled data-->>>\n",
      "('Number of transactions in training set:', 659)\n",
      "('Number of transactions in testing set:', 325)\n",
      "('Total number of transactions are:', 984)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "print(\"Number of transactions in training set:\",len(X_train))\n",
    "print(\"Number of transactions in testing set:\",len(X_test))\n",
    "print(\"Total number of transactions are:\",len(X_train)+len(X_test))\n",
    "\n",
    "print(\"Undersampled data-->>>\")\n",
    "X_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(x_sample, y_sample, test_size=0.33, random_state=1)\n",
    "print(\"Number of transactions in training set:\",len(X_train_undersample))\n",
    "print(\"Number of transactions in testing set:\",len(X_test_undersample))\n",
    "print(\"Total number of transactions are:\",len(X_train_undersample)+len(X_test_undersample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sk/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting an SVC classifier on the undersampled dataset.\n",
    "classifier= SVC(C= 1, kernel= 'rbf', random_state= 0)\n",
    "classifier.fit(X_train_undersample, y_train_undersample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are very interested in the recall score, because that is the metric that will help us try to capture the most fraudulent transactions. If you think how Accuracy, Precision and Recall work for a confusion matrix, recall would be the most interesting:\n",
    "\n",
    "   - Accuracy = (TP+TN)/total\n",
    "   - Precision = TP/(TP+FP)\n",
    "   - Recall = TP/(TP+FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predicting on X_test_undersample\n",
    "y_predict_undersample=classifier.predict(X_test_undersample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[163   6]\n",
      " [ 12 144]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix1=confusion_matrix(y_test_undersample,y_predict_undersample)\n",
    "print(confusion_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy Score of SVC Model on Undersampled data is: 94.1538461538 %\n",
      "The Recall Score of SVC Model on Undersampled data is: 92.3076923077 %\n"
     ]
    }
   ],
   "source": [
    "print'The Accuracy Score of SVC Model on Undersampled data is:',accuracy_score(y_test_undersample,y_predict_undersample)*100,'%'\n",
    "print'The Recall Score of SVC Model on Undersampled data is:',recall_score(y_test_undersample,y_predict_undersample)*100,'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The mean accuracy in %: ', 91.803012907490512)\n",
      "('The standard deviation in % ', 1.5666735820764242)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X=X_train_undersample, y = y_train_undersample, cv = 10)\n",
    "mean_accuracy= accuracies.mean()*100\n",
    "std_accuracy= accuracies.std()*100\n",
    "print(\"The mean accuracy in %: \", accuracies.mean()*100)\n",
    "print(\"The standard deviation in % \", accuracies.std()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10,100,1000],'gamma':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
    "#grid_search = GridSearchCV(estimator = classifier,param_grid = parameters,scoring = 'accuracy',cv = 10,n_jobs = -1)\n",
    "#grid_search = grid_search.fit(X_train_undersample, y_train_undersample)\n",
    "print(\"The Best Score is :\",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The best accuracy using gridSearch is', 0.92867981790591803)\n",
      "('The best parameters for using this model is', {'kernel': 'linear', 'C': 10})\n"
     ]
    }
   ],
   "source": [
    "parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train_undersample, y_train_undersample)\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(\"The best accuracy using gridSearch is\", best_accuracy)\n",
    "\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"The best parameters for using this model is\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
